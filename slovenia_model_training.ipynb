{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hg4p9JFAw1Oh"
      },
      "source": [
        "##Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fQQO4XEKAFZd"
      },
      "outputs": [],
      "source": [
        "import pickle as pkl\n",
        "import builtins"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qaxEcfxvBLR"
      },
      "outputs": [],
      "source": [
        "#update torch and torch vision\n",
        "!pip install -q torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iccw6InHvGq2"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.utils.data\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SKVBi-XAcnj"
      },
      "outputs": [],
      "source": [
        "!pip install fastai==1.0.61"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhW12heUzFjx"
      },
      "outputs": [],
      "source": [
        "import fastai\n",
        "print(\"fastai version: \", fastai.__version__) #1.0.61"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMLu0nFQIjkZ"
      },
      "outputs": [],
      "source": [
        "from fastai.basic_train import *\n",
        "from fastai.vision.data import *\n",
        "from fastai.vision.image import *\n",
        "from fastai.vision.transform import *\n",
        "from fastai.vision.models import *\n",
        "from fastai.vision.learner import *\n",
        "from fastai.vision import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UcNpz_8zxvDG"
      },
      "source": [
        "##Mounting Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5F7wlnUxxaa"
      },
      "outputs": [],
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLMgv0IMw5_s"
      },
      "source": [
        "##Paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wCrdKq9GMAYf"
      },
      "outputs": [],
      "source": [
        "output_path   = Path('/content/gdrive/My Drive/Colab Notebooks/Slovenia/output_9_9')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_4UwaIpOzQO"
      },
      "outputs": [],
      "source": [
        "train_path = output_path/'train_patchlets_64_64'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hqhh6Ab4ezdF"
      },
      "outputs": [],
      "source": [
        "test_path = output_path/'test_patchlets_64_64'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KKNOm1uAbsQD"
      },
      "source": [
        "##Fastaiv1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKGfa2EM0XOT"
      },
      "source": [
        "###Create custom ItemList and LabelList classes to define data loading and display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blSkrdnRRQEm"
      },
      "outputs": [],
      "source": [
        "class SegmentationPklLabelList(SegmentationLabelList):\n",
        "    def open(self, fn):\n",
        "        x = pkl.load(builtins.open(str(fn),'rb'))[None,...].astype(np.float32)\n",
        "        return ImageSegment(torch.tensor(np.squeeze(x, 3)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NjbTOLhR0Zxl"
      },
      "outputs": [],
      "source": [
        "class SegmentationPklList(SegmentationItemList):\n",
        "    _label_cls,_square_show_res = SegmentationPklLabelList,False\n",
        "\n",
        "    def open(self, fn):\n",
        "        x = pkl.load(builtins.open(str(fn),'rb'))\n",
        "        # x = x.transpose([0,3,1,2]).reshape([-1, x.shape[1], x.shape[2]]).astype(np.float32)\n",
        "        x = x.transpose([0,3,1,2]).astype(np.float32) # 31*9*64*64\n",
        "\n",
        "        #print(x.shape)\n",
        "        return Image(torch.tensor(x))\n",
        "\n",
        "    def show_xys(self, xs, ys, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, **kwargs):\n",
        "        \"Show the `xs` (inputs) and `ys` (targets) on a figure of `figsize`.\"\n",
        "        rows = int(np.ceil(math.sqrt(len(xs))))\n",
        "        axs = subplots(rows, rows, imgsize=imgsize, figsize=figsize)\n",
        "        for x,y,ax in zip(xs, ys, axs.flatten()): Image(torch.clamp(x.data[0:3,:,:]*3.5,0,1)).show(ax=ax, y=y, alpha=0.4,**kwargs)\n",
        "        for ax in axs.flatten()[len(xs):]: ax.axis('off')\n",
        "        plt.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO8WkqwEI1qr"
      },
      "outputs": [],
      "source": [
        "classes=['No Data',\n",
        "         'Cultivated_land',\n",
        "         'Forest',\n",
        "         'Grassland',\n",
        "         'Shrubland',\n",
        "         'Water',\n",
        "         'Wetland',\n",
        "         'Artificial_surface',\n",
        "         'Bareland',\n",
        "         ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIo8gRZG0gus"
      },
      "outputs": [],
      "source": [
        "def valid_patch(fn, i=6):\n",
        "    return f'patch_{i}' in str(fn)\n",
        "\n",
        "def get_mask(fn):\n",
        "    return str(fn).replace('feat','targ')\n",
        "\n",
        "def exclude_masks(fn):\n",
        "    return not('targ' in str(fn.name))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SmxnOeIgCK5Y"
      },
      "outputs": [],
      "source": [
        "bs = 2\n",
        "# bs =32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SeLoHWzCiWLi"
      },
      "outputs": [],
      "source": [
        "src = (SegmentationPklList.from_folder(train_path, extensions=['.pkl'], recurse=True, convert_mode='L')\n",
        "      .filter_by_func(exclude_masks)\n",
        "      .split_by_rand_pct(0.1, seed=42)\n",
        "      #.split_by_valid_func(valid_patch)\n",
        "      .label_from_func(get_mask, classes=classes))\n",
        "src"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9pZ_Izrx0lHk"
      },
      "outputs": [],
      "source": [
        "# stats_data = src.databunch(bs=128)\n",
        "stats_data = src.databunch(bs=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FpyPZaSV1XbO"
      },
      "outputs": [],
      "source": [
        "stats_data.batch_stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLtFW2880UDE"
      },
      "outputs": [],
      "source": [
        "x,y = stats_data.one_batch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UFacM4_0hAO"
      },
      "outputs": [],
      "source": [
        "x.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CFn6KtN_vcs4"
      },
      "outputs": [],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2KMV9Ug0muB"
      },
      "outputs": [],
      "source": [
        "means = x.mean(dim=[0,3,4])\n",
        "stds = x.std(dim=[0,3,4])\n",
        "# means = x.mean(dim=[0,2,3])\n",
        "# stds = x.std(dim=[0,2,3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-FVOf0H0vI6"
      },
      "source": [
        "### Define data augmentation and get databunch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Ra5lHfUcEqT"
      },
      "outputs": [],
      "source": [
        "tfms = get_transforms(\n",
        "    do_flip = True,\n",
        "    flip_vert = True,\n",
        "    max_rotate = 20,\n",
        "    max_zoom = 1.1,\n",
        "    max_lighting = 0.,\n",
        "    max_warp = 0.2,\n",
        "    p_affine = 0.75,\n",
        "    p_lighting = 0.,\n",
        "    xtra_tfms = [cutout(n_holes=(5,10), length=(3, 8), p=0.75, use_on_y=False)]\n",
        ")\n",
        "tfms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SkOu19T6hhK"
      },
      "outputs": [],
      "source": [
        "tfms = [tfms[0][1:],[]]# gets rid of resize transformations - they don't work the target mask\n",
        "tfms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfYv0ptN0xmv"
      },
      "outputs": [],
      "source": [
        "data = (src\n",
        "        .transform(tfms,\n",
        "                  tfm_y=True)\n",
        "        .add_test(test_set,tfms=None, tfm_y=False)\n",
        "        .databunch(bs=bs, num_workers = 0)\n",
        "        .normalize(stats=(means,stds))\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1UjI2vD8hgT"
      },
      "outputs": [],
      "source": [
        "data.batch_stats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-2Zu85gM0jE"
      },
      "source": [
        "##Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywGv0w5uOZIy"
      },
      "outputs": [],
      "source": [
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, crit, alpha=1, gamma=2):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.alpha = alpha\n",
        "        self.gamma = gamma\n",
        "        self.crit = crit\n",
        "\n",
        "    def forward(self, inputs, targets, reduction):\n",
        "        loss = self.crit(inputs, targets)\n",
        "        pt = torch.exp(-loss)\n",
        "        F_loss = self.alpha * (1-pt)**self.gamma * loss\n",
        "\n",
        "        if reduction is None:\n",
        "            return F_loss\n",
        "        else:\n",
        "            return torch.mean(F_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4AKl65eRiPE"
      },
      "outputs": [],
      "source": [
        "inv_freq = np.array([0.125314, 0.016608, 0.049898, 0.586994, 2.257207, 24.71436, 0.107695, 98.45247])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cB84EU8bUBmf"
      },
      "outputs": [],
      "source": [
        "inv_freq = [0.,*inv_freq]\n",
        "inv_freq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZB2OrvmRUI4w"
      },
      "outputs": [],
      "source": [
        "inv_prop = torch.tensor(inv_freq/sum(inv_freq)).float().cuda()\n",
        "inv_prop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-BucXSsULtT"
      },
      "outputs": [],
      "source": [
        "focal_loss = FocalLoss(crit=CrossEntropyFlat(axis=1,weight=inv_prop,ignore_index=0)) # For Fastaiv1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yg1T1Z23UTQQ"
      },
      "outputs": [],
      "source": [
        "class myMixUpCallback(LearnerCallback):\n",
        "    \"Callback that creates the mixed-up input and target.\"\n",
        "    def __init__(self, learn:Learner, alpha:float=0.4, stack_x:bool=False, stack_y:bool=True):\n",
        "        super().__init__(learn)\n",
        "        self.alpha,self.stack_x,self.stack_y = alpha,stack_x,stack_y\n",
        "\n",
        "    def on_train_begin(self, **kwargs):\n",
        "        if self.stack_y: self.learn.loss_func = myMixUpLoss(self.learn.loss_func)\n",
        "\n",
        "    def on_batch_begin(self, last_input, last_target, train, **kwargs):\n",
        "        \"Applies mixup to `last_input` and `last_target` if `train`.\"\n",
        "        if not train: return\n",
        "        lambd = np.random.beta(self.alpha, self.alpha, last_target.size(0))\n",
        "        lambd = np.concatenate([lambd[:,None], 1-lambd[:,None]], 1).max(1)\n",
        "        lambd = last_input.new(lambd)\n",
        "\n",
        "        shuffle = torch.randperm(last_target.size(0)).to(last_input.device)\n",
        "        x1, y1 = last_input[shuffle], last_target[shuffle]\n",
        "        if self.stack_x:\n",
        "            new_input = [last_input, last_input[shuffle], lambd]\n",
        "        else:\n",
        "            out_shape = [lambd.size(0)] + [1 for _ in range(len(x1.shape) - 1)]\n",
        "            new_input = (last_input * lambd.view(out_shape) + x1 * (1-lambd).view(out_shape))\n",
        "        if self.stack_y:\n",
        "\n",
        "            new_lambd = torch.distributions.utils.broadcast_all(lambd[:,None,None,None], last_target)[0]\n",
        "\n",
        "            #new_target = torch.cat([last_target[:,None].float(), y1[:,None].float(), new_lambd[:,None].float()], 1)\n",
        "            new_target = torch.stack([last_target.float(), y1.float(), new_lambd.float()], 1)\n",
        "        else:\n",
        "            if len(last_target.shape) == 2:\n",
        "                lambd = lambd.unsqueeze(1).float()\n",
        "            new_target = last_target.float() * lambd + y1.float() * (1-lambd)\n",
        "\n",
        "        return {'last_input': new_input, 'last_target': new_target}\n",
        "\n",
        "    def on_train_end(self, **kwargs):\n",
        "        if self.stack_y: self.learn.loss_func = self.learn.loss_func.get_old()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9T2ZTiLcUUsX"
      },
      "outputs": [],
      "source": [
        "from functools import partial"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBFsD4TuUWlz"
      },
      "outputs": [],
      "source": [
        "class myMixUpLoss(nn.Module):\n",
        "    \"Adapt the loss function `crit` to go with mixup.\"\n",
        "\n",
        "    def __init__(self, crit, reduction='mean'):\n",
        "        super().__init__()\n",
        "        if hasattr(crit, 'reduction'):\n",
        "            self.crit = crit\n",
        "            self.old_red = crit.reduction\n",
        "            setattr(self.crit, 'reduction', 'none')\n",
        "        else:\n",
        "            self.crit = partial(crit, reduction='none')\n",
        "            self.old_crit = crit\n",
        "        self.reduction = reduction\n",
        "\n",
        "    def forward(self, output, target):\n",
        "        if len(target.size()) >= 5:\n",
        "            loss1, loss2 = self.crit(output,target[:,0].long()), self.crit(output,target[:,1].long())\n",
        "            lambd = target[:,2].contiguous().view(-1)\n",
        "            d = (loss1 * lambd  + loss2 * (1-lambd)).mean()\n",
        "        else:  d = self.crit(output, target)\n",
        "        if self.reduction == 'mean': return d.mean()\n",
        "        elif self.reduction == 'sum':            return d.sum()\n",
        "        return d\n",
        "\n",
        "    def get_old(self):\n",
        "        if hasattr(self, 'old_crit'):  return self.old_crit\n",
        "        elif hasattr(self, 'old_red'):\n",
        "            setattr(self.crit, 'reduction', self.old_red)\n",
        "            return self.crit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVoJt00Ikeii"
      },
      "outputs": [],
      "source": [
        "def pixel_acc(inputs, targs):\n",
        "    inputs = inputs.argmax(dim=1)[:,None,...]\n",
        "    return (targs[targs!=0]==inputs[targs!=0]).float().mean()\n",
        "    #return (targs==inputs).float().mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX-dPmvlx69d"
      },
      "source": [
        "##Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "udaLbMD-pjQd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms.functional as TF\n",
        "\n",
        "class DownsampleDilatedBlock(nn.Module):\n",
        "    # This code is hidden, will be released after the acceptance of our manuscript.\n",
        "\n",
        "class DoubleConv(nn.Module):\n",
        "    # This code is hidden, will be released after the acceptance of our manuscript.\n",
        "\n",
        "class Interp(nn.Module):\n",
        "  # This code is hidden, will be released after the acceptance of our manuscript.\n",
        "\n",
        "class SE(nn.Module):\n",
        "    # This code is hidden, will be released after the acceptance of our manuscript.\n",
        "\n",
        "class SE2d(nn.Module):\n",
        "    # This code is hidden, will be released after the acceptance of our manuscript.\n",
        "\n",
        "class DilatedSE3DUNET(nn.Module):\n",
        "    def __init__(self, in_channels=3, out_channels=1, features=[64, 128, 256]):\n",
        "        super(DilatedSE3DUNET, self).__init__()\n",
        "        self.ups = nn.ModuleList()\n",
        "        self.downs = nn.ModuleList()\n",
        "        self.attn = nn.ModuleList()\n",
        "        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Down part of UNET\n",
        "        for feature in features:\n",
        "            self.downs.append(DownsampleDilatedBlock(in_channels, feature))\n",
        "            in_channels = feature\n",
        "\n",
        "        # Up part of UNET\n",
        "        for feature in reversed(features):\n",
        "            self.ups.append(Interp(feature*2, feature))\n",
        "            self.ups.append(DoubleConv(feature*2, feature))\n",
        "\n",
        "        # Attention modules\n",
        "        for feature in reversed(features):\n",
        "          self.attn.append(SE(feature*2))\n",
        "\n",
        "        self.bottleneck = DoubleConv(features[-1], features[-1]*2)\n",
        "        self.attn2d = SE2d(512)\n",
        "        self.final_conv = nn.Conv2d(512, out_channels, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        skip_connections = []\n",
        "\n",
        "        for down in self.downs:\n",
        "            x = down(x)\n",
        "            skip_connections.append(x)\n",
        "            x = self.pool(x)\n",
        "\n",
        "        x = self.bottleneck(x)\n",
        "        skip_connections = skip_connections[::-1]\n",
        "\n",
        "        for idx in range(0, len(self.ups), 2):\n",
        "            x = self.ups[idx](x)\n",
        "            skip_connection = skip_connections[idx//2]\n",
        "\n",
        "            if x.shape[2:] != skip_connection.shape[2:]:\n",
        "                es = x.shape[2:]\n",
        "                ds = skip_connection.shape[2:]\n",
        "                skip_connection = skip_connection[\n",
        "                            :,\n",
        "                            :,\n",
        "                            ((ds[0] - es[0]) // 2):((ds[0] + es[0]) // 2),\n",
        "                            ((ds[1] - es[1]) // 2):((ds[1] + es[1]) // 2),\n",
        "                            ((ds[2] - es[2]) // 2):((ds[2] + es[2]) // 2),\n",
        "                            ]\n",
        "\n",
        "            concat_skip = torch.cat((skip_connection, x), dim=1)\n",
        "            att = self.attn[idx//2](concat_skip)\n",
        "            x = self.ups[idx+1](att)\n",
        "        x = x.reshape([x.shape[0], x.shape[1]*x.shape[2], 64, 64])\n",
        "        x = self.attn2d(x)\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzz0SV6_plVh"
      },
      "outputs": [],
      "source": [
        "def test():\n",
        "    x = torch.randn((4, 31, 9, 64, 64))\n",
        "    model = DilatedSE3DUNET(in_channels=31, out_channels=11)\n",
        "    #print(model)\n",
        "    preds = model(x)\n",
        "    #print(preds)\n",
        "    print(\"preds.shape:\", preds.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6l5xVBO6poRG"
      },
      "outputs": [],
      "source": [
        "test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv9A5YXiB1sD"
      },
      "source": [
        "##Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(data,\n",
        "                DilatedSE3DUNET(in_channels=23, out_channels=11),\n",
        "                loss_func=focal_loss,\n",
        "                metrics=[pixel_acc],\n",
        "                callback_fns=[partial(myMixUpCallback,alpha=0.4, stack_y=True)])"
      ],
      "metadata": {
        "id": "Z89enEqiO8j7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsMnKdCrqNKT"
      },
      "outputs": [],
      "source": [
        "learn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VsrJWWYOqNKU"
      },
      "outputs": [],
      "source": [
        "learn.lr_find()\n",
        "learn.recorder.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2ix2MxvqNKV"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(5, max_lr = 1e-2, wd = 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Z7eXNXsqNKV"
      },
      "outputs": [],
      "source": [
        "learn.unfreeze()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rgg2p9FqNKW"
      },
      "outputs": [],
      "source": [
        "learn.fit_one_cycle(20, max_lr=1e-3, wd=0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSB1-iaHqNKW"
      },
      "outputs": [],
      "source": [
        "learn.save('Final_focal_loss_31_9_64_64')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learn.export('/content/gdrive/My Drive/Colab Notebooks/Slovenia/Final_focal_loss_31_9_64_64.pkl')"
      ],
      "metadata": {
        "id": "p9PInPp68jwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "hg4p9JFAw1Oh",
        "UcNpz_8zxvDG",
        "FucjAImo62YI",
        "nLMgv0IMw5_s",
        "yKGfa2EM0XOT",
        "G-FVOf0H0vI6",
        "Smhpjtwc2Xkw",
        "a-2Zu85gM0jE",
        "GsS25Dwa0-Cl",
        "B3Z_Od1IyzJ7",
        "JSHOocpOyOAb",
        "Bajpjb-mWFs0",
        "62k98bDiLwdS",
        "OwaCz4HzVjfp",
        "iD_e7friyP44",
        "yoC3YHLFTXjV",
        "3KL5HjltCX7M",
        "IfgHtr_x4RAH",
        "E4Ar2uPc9KsG",
        "WDY_f1gTFOhK",
        "5bostQODSWOM",
        "NzByL75pphnW",
        "1fF8taf3OKPT",
        "bKRyAlQ7WG9I",
        "eE4dT-ZscbD9",
        "uDSqhGuUVeqQ",
        "1S-FkV5JjlEJ",
        "Y0JSGsfGWfA7",
        "wC6LsIDeKXCs",
        "xtuJoILwWGLG",
        "jdo6DZtoGaQL",
        "WjAU0SVOZjpM",
        "AYQrWeJDDDDf",
        "ugbijpe044-O",
        "uqoI-x0gcs78",
        "XUe6VGEuCa6D",
        "_I1MiF68N3sI",
        "a5Bq_FbTzaSL",
        "kDwt9vOqV3q2",
        "5-KV3-Klz4ed",
        "9WhFvHC2jwxO",
        "w3xUMSc4McvZ",
        "fpsxeCJ_cl-q",
        "Btr-jsVfWo-t",
        "4jSJeLgKo3_Y",
        "11ZkJ4IkwkN2",
        "0y2DvUiZeWEF",
        "h-cGRty2k-XH",
        "zKsNmMv-cxB2",
        "MiLN4MbtN-vN",
        "yTdRo6wlOF0n",
        "7Z_ZwYfalPP-",
        "9LNucNaAlPP_",
        "W30NCw4xgJj6",
        "18nDbdWIgJj7",
        "7xqlQE37gJj9",
        "9sqcRiGzs1RL",
        "r-ZCEYoxs1RN",
        "bhiXfu10s1RP",
        "M1DGjJkIqTP0",
        "_m0K23LRqTP1",
        "nwy_LtW_qTP6",
        "YeM-banKaU0Q",
        "-dE5C94iaU0Q",
        "9HRQKtn1aU0X",
        "82ZH2oefDOof",
        "XCwfnvliDOof",
        "V2WIFx-8DOoj",
        "n8uo3paD5aew",
        "_EC9-CeJ5aex",
        "PW_ikowz5ae1",
        "8AUQIavkczGu",
        "DmPaYe5eczGv",
        "fHimqlZTczGz",
        "ZYyxainvDvL4",
        "cQIN5oIEDvL5",
        "5lOlq3KYDvL_",
        "dsW4_RqZOV34",
        "9PNWwnbiOV35",
        "yrl92pQ9OV3-",
        "kT-Fj7fNzgf9",
        "gi_QfWY8zgf-",
        "D3BPh3rTzggE",
        "lysXir_VWD2E",
        "HC0KR3HRWD2F",
        "uoZVjDZQWD2K",
        "oAgRFYSZhman",
        "SKaPhl2thmao",
        "UqrnIci7hmay",
        "wLkZNgqmqdRd",
        "4MvLnP_GqdRe",
        "JaU2_vziqdRi",
        "5kFtQpKL8Mol",
        "HhwD5Ecg8Mom",
        "kzgwJbzsRJIV",
        "6LEtTNsFRJIV",
        "Xln5IwSARJIX",
        "m4yZesJfjvip",
        "wwsRFPxkjviq",
        "tmORkfr6jviu",
        "VwsFCq4vW2VK",
        "Evnx5b0bW2VL",
        "Akma2ZHYW2VS",
        "Zac5kGRcqV3A",
        "eBlgdaZwwwBL",
        "XGEau6P5GW0v",
        "FjkTtLwdGW0w",
        "1Orv1-o6GW01",
        "DR1Iod3yhUIV",
        "XKLFH3_ghUIW",
        "iNlbcApHhUId",
        "QuBCReQuaOIf",
        "mCwF4s__aOIg",
        "t0G1ICIxaOIi",
        "cI80fpaR3eS0",
        "5griXJrc3eS1",
        "BJOP-qNu3eS2",
        "9zuarNJS6mpv",
        "t4weitHP6mpx",
        "Z2ZXqqxR6mp5",
        "-nVCmQD4Rqx5",
        "CMjKZ3EGRqx6",
        "W8wHqQcXRqx-",
        "4kqbYCAcXgUZ",
        "wpb5aUiLXgUa",
        "8TwuFKjr3jOs",
        "-bdmoKFw3jOs",
        "bXLzT-km3jOw"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}